# 整体重构

最近将博客整体重构了一下
+ 将原本的前后端不分离，改为了前后端分离的架构。前端使用的是Vue。因为Vue的组件化，以及数据交互基本都为axios异步请求，所以整体流畅度提升了不少。也是明白了前后端交互的整体流程。
+ 更改了登录的流程。
+ 增加了Kafka中间件，添加了消息发送功能。消息查看页面，包括消息处理，评论跳转。
+ 所有服务均通过容器化部署，通过docker-compose进行统一的部署与管理。
+ 进行了一些美化（如添加CSS实现在特定页面获取数据时会有加载动画）

## 登录流程更改
原本是将jwt存入cookie中，那么每次请求会携带cookie，后端可以通过cookie判断是否登录，为了避免跨域请求，可以将cookie存在登陆中心，这样就不会因为跨域而无法携带cookie了。现改为，登陆后将jwt存在localstorage中，前端每次请求都会将localstorage中的jwt存入请求头中，这样每次请求后端都可以判断用户是否登录以及权限。同时，因为前端JS的存在，可以有效地避免CSRF（因为必须要点击我自己的网页），可以说是同时避免了跨域请求以及CSRF。

## Kafka实现消息发送
在评论保存后，利用mq进行异步的message存储

```Java
commentService.saveComment(comment);
// ...
messageProducer.fireMessage(message);
```

MessageProducer

```Java
@Component
public class MessageProducer {
    @Autowired
    private KafkaTemplate kafkaTemplate;

    //处理事件
    public void fireMessage(Message message) {
        //将事件发布到指定的主题
        kafkaTemplate.send("TOPIC_COMMENT", JSONObject.toJSONString(message));
    }
}
```

MessageConsumer

```Java
@Component
public class MessageConsumer {
    private static Logger logger = LoggerFactory.getLogger(MessageConsumer.class);

    @Autowired
    private MessageService messageService;

    @KafkaListener(topics = {"TOPIC_COMMENT"})
    public void handleComment(ConsumerRecord record) {
        if (record == null || record.value() == null) {
            logger.error("消息的内容为空");
            return;
        }
        Message message = JSONObject.parseObject(record.value().toString(), Message.class);
        if (message == null) {
            logger.error("消息格式错误");
            return;
        }
        messageService.addMessage(message);
    }
}
```

## docker-compose批量容器管理

编写 Dockerfile

```yml
# FROM java:8 (Docker官网弃用了Java镜像)
FROM openjdk:8

EXPOSE 81

ADD myblogForVue.jar myblogForVue.jar

# ENTRYPOINT nohup java -Djasypt.encryptor.password=123 -jar myblogForVue.jar --spring.profiles.active=pro >> nohup.out 2>&1 &
ENTRYPOINT java -Djasypt.encryptor.password=123 -jar /myblogForVue.jar
```

编写docker-compose.yml

```yml
version: '3'

services:
  myblog:
    image: myblog
    # 通过同一级的 Dockerfile 构建项目镜像
    build:
      context: ./
      dockerfile: Dockerfile
    # 暴露项目端口
    ports:
      - 81:81
  nginx:
    image: nginx:1.14.1
    ports:
      - 80:80
      - 443:443
    volumes:
      - /etc/nginx/nginxForVue.conf:/etc/nginx/nginx.conf
      - /usr/local/myblog/certificate:/usr/local/myblog/certificate
      - /usr/local/myblogForVue/dist:/usr/local/myblogForVue/dist
    privileged: true #这个必须要，解决nginx的文件调用的权限问题
  mysql:
    image: mysql:8.0
    ports:
      - 3306:3306
    environment:
      - MYSQL_ROOT_PASSWORD=123
    volumes:
      - /usr/local/src/mysql-8.0/myblog/data:/var/lib/mysql
      - /usr/local/src/mysql-8.0/myblog/my.conf:/etc/my.conf
      - /usr/local/src/mysql-8.0/myblog/log:/var/log/mysql
  redis:
    image: redis:latest
    ports:
      - 6379:6379
    volumes:
      - /usr/local/src/redis-6.2.1/myblog/data:/data
      - /usr/local/src/redis-6.2.1/myblog/redis.conf:/etc/redis.conf
    command: redis-server /etc/redis.conf
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - 2181:2181
    restart: always
  kafka:
    image: wurstmeister/kafka
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://106.14.241.163:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_BROKER_ID: 0
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms16M"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always
```

这里我将mysql和redis的data都进行了挂载，方便通过crontab定时任务来保存数据副本。